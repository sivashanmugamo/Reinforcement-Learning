{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0d106dbbdda2c87ab37e0e211bc0dfbac0ab305ec9f20e6eb67160d2993429803",
   "display_name": "Python 3.7.9 64-bit ('ML Environment': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, time, pickle, random\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE= torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_POS= [0, 0]\n",
    "DIAMOND_POS= [1, 3]\n",
    "COIN_POS= [3, 2]\n",
    "MONSTER_POS= [2, 1]\n",
    "GOAL_POS= [3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STATES= 16\n",
    "N_ACTIONS= 4\n",
    "MAX_TIMESTEPS= 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_LOOKUP= dict()\n",
    "ACTION_LOOKUP= {0: 'Down', 1: 'Up', 2: 'Right', 3: 'Left'}\n",
    "\n",
    "k= 0\n",
    "for i in range(4):\n",
    "  for j in range(4):\n",
    "    STATE_LOOKUP[(i, j)]= k\n",
    "    k+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(gym.Env):\n",
    "  metadata= {'render.modes': []}\n",
    "\n",
    "  def __init__(self) -> None:\n",
    "    '''\n",
    "    Initializes the number of states, action, & maximum timestep of the environment\n",
    "    '''\n",
    "\n",
    "    self.observation_space= spaces.Discrete(N_STATES)\n",
    "    self.action_space= spaces.Discrete(N_ACTIONS)\n",
    "    self.max_timesteps= MAX_TIMESTEPS\n",
    "\n",
    "  def reset(self) -> int:\n",
    "    '''\n",
    "    Resets the environment to its default setup\n",
    "\n",
    "    Output:\n",
    "      observation: 2-element list - Coordinates of the agent's default position in the grid\n",
    "    '''\n",
    "\n",
    "    self.timestep= 0\n",
    "\n",
    "    self.agent_pos= AGENT_POS.copy()\n",
    "    self.diamond_pos= DIAMOND_POS.copy()\n",
    "    self.coin_pos= COIN_POS.copy()\n",
    "    self.monster_pos= MONSTER_POS.copy()\n",
    "    self.goal_pos= GOAL_POS.copy()\n",
    "\n",
    "    self.state= np.zeros((4, 4))\n",
    "\n",
    "    self.state[tuple(self.agent_pos)]= 1\n",
    "    self.state[tuple(self.diamond_pos)]= 5\n",
    "    self.state[tuple(self.coin_pos)]= 3\n",
    "    self.state[tuple(self.monster_pos)]= -5\n",
    "    self.state[tuple(self.goal_pos)]= 10\n",
    "    \n",
    "    agent_state= self.agent_pos\n",
    "\n",
    "    return STATE_LOOKUP[tuple(agent_state)]\n",
    "\n",
    "  def step(self, action: int) -> tuple:\n",
    "    '''\n",
    "    1. Moves the agent as per the given action\n",
    "    2. Sets the rewards per state in the environment\n",
    "    3. Calculates the reward of the new state\n",
    "\n",
    "    Input:\n",
    "      action: int - Action to be performed\n",
    "\n",
    "    Output:\n",
    "      action: int - Action taken\n",
    "      observation: 2-element list\n",
    "      reward: int - State reward\n",
    "      done: bool - Denotes if the learning is complete (or) goal is reached\n",
    "      info: dict\n",
    "    '''\n",
    "\n",
    "    # Initializing the grid\n",
    "    self.state= np.zeros((4, 4))\n",
    "\n",
    "    # Move the agent\n",
    "    if action == 0: # Go down one step\n",
    "      self.agent_pos[0] += 1\n",
    "    if action == 1: # Go up one step\n",
    "      self.agent_pos[0] -= 1\n",
    "    if action == 2: # Go right one step\n",
    "      self.agent_pos[1] += 1\n",
    "    if action == 3: # Go left one step\n",
    "      self.agent_pos[1] -= 1\n",
    "\n",
    "    # To keep the agent within the confines of the environment\n",
    "    self.agent_pos= np.clip(self.agent_pos, 0, 3)\n",
    "\n",
    "    # Initialize the state rewards\n",
    "    self.state[tuple(self.agent_pos)]= 1\n",
    "    self.state[tuple(self.diamond_pos)]= 5\n",
    "    self.state[tuple(self.coin_pos)]= 3\n",
    "    self.state[tuple(self.monster_pos)]= -5\n",
    "    self.state[tuple(self.goal_pos)]= 10\n",
    "\n",
    "    agent_state= self.agent_pos\n",
    "\n",
    "    # Calculates the reward for the action\n",
    "    reward= 0\n",
    "    if (self.agent_pos == self.diamond_pos).all():\n",
    "      reward += 5\n",
    "    if (self.agent_pos == self.coin_pos).all():\n",
    "      reward += 3\n",
    "    if (self.agent_pos == self.monster_pos).all():\n",
    "      reward -= 5\n",
    "    if (self.agent_pos == self.goal_pos).all():\n",
    "      reward += 10\n",
    "\n",
    "    # Timestep increment\n",
    "    self.timestep += 1\n",
    "\n",
    "    done= True if ((self.timestep >= self.max_timesteps) or (self.agent_pos == self.goal_pos).all()) else False\n",
    "    info= {}\n",
    "\n",
    "    return (STATE_LOOKUP[tuple(agent_state)], reward, done, info)\n",
    "\n",
    "  def render(self) -> None:\n",
    "    '''\n",
    "    Provides pictorial representation of environment\n",
    "    '''\n",
    "\n",
    "    plt.imshow(self.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}